{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000  train samples\n",
      "10000  train samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 126s - loss: 0.3339 - acc: 0.8986 - val_loss: 0.0798 - val_acc: 0.9753\n",
      "Test loss: 0.0797709787564\n",
      "Test accuracy 0.9753\n",
      "INFO:tensorflow:Restoring parameters from out/mnist_convnet.chkp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from out/mnist_convnet.chkp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 8 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 8 variables to const ops.\n",
      "81 ops in the final graph.\n",
      "graph saved!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "import os\n",
    "import os.path as path\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], ' train samples')\n",
    "print(x_test.shape[0], ' train samples')\n",
    "\n",
    "# convert class vectors to binary class matrix\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# building model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy', score[1])\n",
    "\n",
    "\n",
    "# export model\n",
    "model_name = 'mnist_convnet'\n",
    "\n",
    "file_path = 'out'\n",
    "input_graph_file = model_name + '.pbtxt'\n",
    "input_graph_file_path = file_path + '/' + input_graph_file\n",
    "checkpoint_file = model_name + '.chkp'\n",
    "checkpoint_file_path = file_path + '/' + checkpoint_file\n",
    "restore_op_name = \"save/restore_all\"\n",
    "filename_tensor_name = \"save/Const:0\"\n",
    "output_frozen_graph_file_path = file_path + '/frozen_' + model_name + '.pb'\n",
    "output_optimized_graph_file_path = file_path + '/optimized_' + model_name + '.pb'\n",
    "\n",
    "input_node_names = \"conv2d_1_input\"\n",
    "output_node_names = \"dense_2/Softmax\"\n",
    "\n",
    "if not path.exists(file_path):\n",
    "    os.mkdir(file_path)\n",
    "    \n",
    "# Save the graph\n",
    "tf.train.write_graph(K.get_session().graph_def, file_path, input_graph_file)\n",
    "\n",
    "# Save a checkpoint\n",
    "saver = tf.train.Saver()\n",
    "saver.save(K.get_session(), checkpoint_file_path)\n",
    "\n",
    "# Freeze the graph. convert variables in the checkpoint file into Const Ops\n",
    "freeze_graph.freeze_graph(input_graph_file_path, None, False, checkpoint_file_path,\n",
    "                          output_node_name, restore_op_name, filename_tensor_name, \n",
    "                          output_frozen_graph_file_path, True, \"\")\n",
    "\n",
    "# Optimize the model file\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open(output_frozen_graph_file_path, \"rb\") as f:\n",
    "    data = f.read()\n",
    "    input_graph_def.ParseFromString(data)\n",
    "    \n",
    "output_graph_def = optimize_for_inference_lib.optimize_for_inference(\n",
    "                    input_graph_def, \n",
    "                    [input_node_names], # an array of the input node(s)\n",
    "                    [output_node_names], # an array of output nodes\n",
    "                    tf.float32.as_datatype_enum)\n",
    "\n",
    "# Save the optimized graph\n",
    "with tf.gfile.FastGFile(output_optimized_graph_file_path, \"wb\") as f:\n",
    "    f.write(output_graph_def.SerializeToString())\n",
    "    \n",
    "print (\"graph saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
